# -*- coding: utf-8 -*-
"""fcc_sms_text_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q1lw7HPVrXmtgwyFvgUnexvyOz0bN8Oh
"""

!pip install keras_cv
!pip install --upgrade tensorflow
import tensorflow as tf
from tensorflow import keras
!pip install tensorflow-hub
import tensorflow_hub as hub
import pandas as pd
!pip install tensorflow-datasets
import tensorflow_datasets as tfds
import numpy as np
import matplotlib.pyplot as plt
from keras import layers

# get data files from fcc
!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv
!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv

train_file_path = "train-data.tsv"
test_file_path = "valid-data.tsv"

df_train = pd.read_csv(train_file_path, sep='\t', header = 0, names = ['label', 'text'])
df_train.head()

df_valid = pd.read_csv(test_file_path, sep = '\t', header = 0, names = ['label', 'text'])
df_valid.head()

train_text = df_train.text.values
df_train.label[df_train.label == 'spam'] = 0
df_train.label[df_train.label == 'ham'] = 1
train_label = df_train.label.values
val_text = df_valid.text.values
df_valid.label[df_valid.label == 'spam'] = 0
df_valid.label[df_valid.label == 'ham'] = 1
val_label = df_valid.label.values
print(train_label, train_label.shape)

string = ''
for i in range(len(val_text)):
  string += val_text[i]
for i in range(len(train_text)):
  string += train_text[i]
vocab = sorted(set(string))
print(vocab)
print(len(vocab))
input_length = 80

from keras_preprocessing.sequence import pad_sequences
def convert_text(text):
  char2idx = {u:i for i, u in enumerate(vocab)}
  indx2char = np.array(vocab)
  def text_to_int(text):
    arr = list()
    for i in range(len(text)):
      arr.append([char2idx[c] for c in text[i] if c in char2idx])
    return np.asarray(arr, dtype = object)
  text_as_int = text_to_int(text)
  text_as_int = pad_sequences(text_as_int, input_length)
  text_as_int = np.array([item[0:] for item in text_as_int]).astype('int64')
  dataset = text_as_int.reshape(len(text), input_length)
  dataset = tf.convert_to_tensor(dataset)
  return dataset

convert_text(train_text)

train_dataset = convert_text(train_text)
val_dataset = convert_text(val_text)
train_label = train_label.astype('int64')
train_label = train_label.reshape(len(train_label), 1)
train_label = tf.convert_to_tensor(train_label)
val_label = val_label.astype('int64')
val_label = val_label.reshape(len(val_label), 1)
val_label = tf.convert_to_tensor(val_label)

print(train_dataset.shape)
print(train_label.shape)
print(val_dataset.shape)
print(val_label.shape)

model = keras.Sequential([
    layers.Embedding(input_dim = len(vocab)+1, output_dim = 64, input_length = input_length, mask_zero = True), 
    layers.LSTM(64, return_sequences = True),
    layers.LSTM(128, return_sequences = False),
    layers.Dense(32, activation = 'sigmoid'),
    layers.Dense(1, activation = 'sigmoid')
])
model.summary()

model.compile(optimizer = 'rmsprop', loss = tf.keras.losses.BinaryCrossentropy(from_logits = False), metrics = tf.keras.metrics.FalsePositives())
model.fit(train_dataset, train_label, batch_size = 1, epochs = 3, validation_data = (val_dataset, val_label))

def predict_message(pred_text):
  char2idx = {u:i for i, u in enumerate(vocab)}
  arr = list()
  for i in range(len(pred_text)):
    arr.append([char2idx[c] for c in pred_text[i] if c in char2idx])
  pred_text = np.array(arr).astype('int64')
  pred_text = pred_text.reshape(1, len(pred_text))
  pred_text = pad_sequences(pred_text, input_length)
  prediction = model.predict(tf.convert_to_tensor(pred_text))
  probability = prediction[0][0]
  if probability >= 0.5:
    output = [probability, 'ham']
  else:
    output = [probability, 'spam']
  return output
